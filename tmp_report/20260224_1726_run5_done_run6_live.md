# compile_sweep_v1 milestone: run5 complete, run6 in progress

- timestamp: 2026-02-24 17:26:40 +0800
- experiment: `/mnt/stepeval/yangxiaobo/cache/nanochat/tmp_exp/20260224_164636_moe-fp8-compile-sweep-v1`

## Queue transition

- `17:24:24 +0800`: finished `moe_fp8_experts_nocompile_long_retest` (status=0)
- `17:24:26 +0800`: started `moe_bf16_experts_nocompile_long_retest`
- queue handoff remained contiguous; no manual restart needed.

## Completed run5 metrics

From `tmp_report/metrics/moe_fp8_ablation_summary.csv`:

- run: `moe_fp8_experts_nocompile_long_retest`
- status: `completed`
- tail50 tok/sec: `359,711`
- tail50 bf16_mfu: `4.3524`
- tail50 dt: `1462.56ms`
- peak memory: `22,862.51 MiB`
- total time: `8.53m`

## Live run6 metrics

Current run: `moe_bf16_experts_nocompile_long_retest`

- observed steps: `60`
- tail50 tok/sec: `601,536`
- tail50 bf16_mfu: `7.2790`
- tail50 dt: `996.14ms`

Recent live lines show tok/sec climbing into `~650k-750k` as warmup effects fade.

## Interim interpretation

- `compile=none` + FP8 experts (run5) is substantially slower than dynamic compile FP8 experts (`359k` vs `785k` tail50 tok/sec).
- `compile=none` + BF16 experts (run6, live) is already significantly faster than run5, indicating FP8 quant/dequant overhead dominates when compile is disabled.
- This supports continuing with compile-focused routes (dynamic/static shape stabilization) rather than eager FP8 expert execution.
